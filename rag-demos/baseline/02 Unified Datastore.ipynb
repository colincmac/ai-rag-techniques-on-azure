{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CosmosDB as a single source"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prereqs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div></div><div></div><div><strong>Installed Packages</strong><ul><li><span>Azure.AI.OpenAI, 2.0.0-beta.3</span></li><li><span>Azure.Identity, 1.12.0</span></li><li><span>Azure.Search.Documents, 11.6.0</span></li><li><span>CsvHelper, 33.0.1</span></li><li><span>Microsoft.Azure.Cosmos, 3.44.0-preview.1</span></li><li><span>Microsoft.Data.Analysis, 0.21.0</span></li><li><span>System.Linq.Async, 6.0.1</span></li></ul></div></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div><div></div><div></div><div><strong>Installed Packages</strong><ul><li><span>Azure.Monitor.OpenTelemetry.Exporter, 1.3.0</span></li><li><span>Microsoft.ML.Tokenizers, 0.22.0-preview.24378.1</span></li><li><span>Microsoft.SemanticKernel, 1.19.0</span></li><li><span>Microsoft.SemanticKernel.Connectors.AzureCosmosDBNoSQL, 1.19.0-alpha</span></li><li><span>Microsoft.SemanticKernel.Connectors.OpenAI, 1.19.0</span></li><li><span>Microsoft.SemanticKernel.Planners.OpenAI, 1.19.0-preview</span></li></ul></div></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#!import code/Setup.cs\n",
    "#!import code/VectorModels.cs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vector Store Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Database Configuration: Overview\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Understand Index Type, Vector Data Type, and Distance Functions**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **`Vector Index Type`**\n",
    "\n",
    "This option determines how vectors are indexed within Cosmos DB to optimize search performance.\n",
    "\n",
    "- **`flat` Index Type**: Use for low-dimensional, exact searches on smaller datasets.\n",
    "- **`quantizedFlat` Index Type**: Choose when you need to balance performance and storage with acceptable accuracy loss in high-dimensional data.\n",
    "- **`diskANN` Index Type**: Opt for large-scale, high-dimensional datasets where approximate searches suffice, and speed is critical.\n",
    "\n",
    "<details>\n",
    "<summary>\n",
    "Options\n",
    "</summary>\n",
    "\n",
    "- **`flat`**: Stores vectors alongside other indexed properties without additional indexing structures. Supports up to **505 dimensions**.\n",
    "\n",
    "  **When to Use:**\n",
    "\n",
    "  - **Low-dimensional data**: Ideal for applications with vectors up to 505 dimensions.\n",
    "  - **Exact search requirements**: When you need precise search results.\n",
    "  - **Small to medium datasets**: Efficient for datasets where the index size won't become a bottleneck.\n",
    "\n",
    "    **Real-World Scenario:**\n",
    "\n",
    "    - **Customer Segmentation**: A retail company uses customer feature vectors (age, income, purchase history) with dimensions well below 505 to segment customers. Exact matches are important for targeted marketing campaigns.\n",
    "\n",
    "- **`quantizedFlat`**: Compresses (quantizes) vectors before indexing, improving performance at the cost of some accuracy. Supports up to **4096 dimensions**.\n",
    "\n",
    "  **When to Use:**\n",
    "\n",
    "  - **High-dimensional data with storage constraints**: Suitable for vectors up to 4096 dimensions where storage efficiency is important.\n",
    "  - **Performance-critical applications**: When reduced latency and higher throughput are needed.\n",
    "  - **Acceptable accuracy trade-off**: Minor losses in accuracy are acceptable for performance gains.\n",
    "\n",
    "    **Real-World Scenario:**\n",
    "\n",
    "    - **Mobile Image Recognition**: An app recognizes objects using high-dimensional image embeddings. Quantization reduces the storage footprint and improves search speed, crucial for mobile devices with limited resources.\n",
    "\n",
    "- **`diskANN`**: Utilizes the DiskANN algorithm for approximate nearest neighbor searches, optimized for speed and efficiency. Supports up to **4096 dimensions**.\n",
    "\n",
    "  **When to Use:**\n",
    "\n",
    "  - **Large-scale, high-dimensional data**: Best for big datasets where quick approximate searches are acceptable.\n",
    "  - **Real-time applications**: When fast response times are critical.\n",
    "  - **Scalability needs**: Suitable for applications expected to grow significantly.\n",
    "\n",
    "  **Real-World Scenario:**\n",
    "\n",
    "  - **Semantic Search Engines**: A search engine indexes millions of documents using embeddings from language models like BERT (768 dimensions). DiskANN allows users to get fast search results by efficiently handling high-dimensional data.\n",
    "</details>\n",
    "\n",
    "---\n",
    "\n",
    "#### **`Vector Data Type`**\n",
    "\n",
    "Specifies the data type of the vector components.\n",
    "\n",
    "- **`float32` Datatype**: Default choice for precision; use when storage is less of a concern.\n",
    "- **`uint8` and `int8` Datatypes**: Use for storage efficiency, particularly when data can be quantized.\n",
    "\n",
    "<details>\n",
    "<summary>Options</summary>\n",
    "\n",
    "- **`float32`** (default): 32-bit floating-point numbers.\n",
    "\n",
    "  **When to Use:**\n",
    "\n",
    "  - **High precision requirements**: Necessary when the application demands precise calculations.\n",
    "  - **Standard ML embeddings**: Most machine learning models output float32 vectors.\n",
    "\n",
    "  **Real-World Scenario:**\n",
    "\n",
    "  - **Scientific Simulations**: In climate modeling, vectors represent complex data where precision is vital for accurate simulations and predictions.\n",
    "\n",
    "- **`uint8`**: 8-bit unsigned integers.\n",
    "\n",
    "  **When to Use:**\n",
    "\n",
    "  - **Memory optimization**: Reduces storage needs when precision can be sacrificed.\n",
    "  - **Quantized models**: When vectors are output from models that already quantize data.\n",
    "\n",
    "  **Real-World Scenario:**\n",
    "\n",
    "  - **Basic Image Features**: Storing color histograms for image retrieval systems, where each bin can be represented with an 8-bit integer.\n",
    "\n",
    "- **`int8`**: 8-bit integer with potentially specialized encoding (interpretation may vary; assuming it's an 8-bit integer with logarithmic encoding).\n",
    "\n",
    "  **When to Use:**\n",
    "\n",
    "  - **Custom quantization schemes**: When using specialized compression techniques that map floating-point values to an 8-bit integer scale.\n",
    "  - **Edge devices**: Ideal for applications on devices with extreme memory limitations.\n",
    "\n",
    "  **Real-World Scenario:**\n",
    "\n",
    "  - **Audio Fingerprinting**: Compressing audio feature vectors for song recognition apps where storage and quick retrieval are essential.\n",
    "</details>\n",
    "\n",
    "---\n",
    "#### **`Dimension Size`**\n",
    "\n",
    "The length of the vectors being indexed. Ranges from 0-4096, default is **1536**.\n",
    "<details>\n",
    "<summary>Options</summary>\n",
    "\n",
    "\n",
    "**When to Consider Lower Dimensions (≤ 505):**\n",
    "\n",
    "  - **Simpler models**: Applications using basic embeddings or feature vectors.\n",
    "  - **Flat index type**: Required when using the `flat` index type due to its dimension limit.\n",
    "\n",
    "  *Real-World Scenario:*\n",
    "\n",
    "  - **Keyword Matching**: Using low-dimensional TF-IDF vectors for document similarity in a content management system.\n",
    "\n",
    "  **When to Consider Higher Dimensions (506 - 4096):**\n",
    "\n",
    "  - **Complex models**: Deep learning applications with high-dimensional embeddings.\n",
    "  - **Advanced search features**: When richer representations of data are necessary for accuracy.\n",
    "\n",
    "  *Real-World Scenario:*\n",
    "\n",
    "  - **Face Recognition**: Using high-dimensional embeddings (e.g., 2048 dimensions) to represent facial features for security systems.\n",
    "</details>\n",
    "\n",
    "---\n",
    "\n",
    "#### **`Distance Function`**\n",
    "\n",
    "Determines how similarity between vectors is calculated. Select based on the nature of similarity in your application—`cosine` for orientation, `dot product` when magnitude matters, and `euclidean` for spatial relevance.\n",
    "\n",
    "<details>\n",
    "<summary>Options</summary>\n",
    "\n",
    "- **`cosine`**: Measures the cosine of the angle between vectors.\n",
    "\n",
    "  **When to Use:**\n",
    "\n",
    "  - **Orientation-focused similarity**: When the magnitude is less important than the direction.\n",
    "  - **Normalized data**: Ideal when vectors are normalized to unit length.\n",
    "\n",
    "  **Real-World Scenario:**\n",
    "\n",
    "  - **Document Similarity**: In text analytics, comparing documents based on topic similarity where word counts are normalized.\n",
    "\n",
    "- **`dot product`**: Computes the scalar product of two vectors.\n",
    "\n",
    "  **When to Use:**\n",
    "\n",
    "  - **Magnitude matters**: When both direction and magnitude are significant.\n",
    "  - **Machine learning models**: Often used in recommendation systems where strength of preferences is important.\n",
    "\n",
    "  **Real-World Scenario:**\n",
    "\n",
    "  - **Personalized Recommendations**: Matching users to products by calculating the dot product of user and item embeddings in a collaborative filtering system.\n",
    "\n",
    "- **`euclidean`**: Calculates the straight-line distance between vectors.\n",
    "\n",
    "  **When to Use:**\n",
    "\n",
    "  - **Spatial distance relevance**: When physical distance correlates with similarity.\n",
    "  - **High-dimensional data**: Suitable for embeddings where both magnitude and direction impact similarity.\n",
    "\n",
    "  **Real-World Scenario:**\n",
    "\n",
    "  - **Anomaly Detection**: Identifying outliers in network traffic patterns by measuring Euclidean distances in feature space.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Option Combinations and Preferred Use-Cases**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "#### **Combination 1: Low-Dimensional, Exact Searches**\n",
    "\n",
    "- **`vectorIndexType`**: `flat`\n",
    "- **`datatype`**: `float32`\n",
    "- **`dimensions`**: ≤ 505\n",
    "- **`distanceFunction`**: `cosine`\n",
    "\n",
    "**Real-World Scenario:**\n",
    "\n",
    "- **Small-Scale Text Classification**: A startup builds a news categorization tool using word embeddings (300 dimensions). Exact cosine similarity searches ensure accurate article tagging without the overhead of approximate methods.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Combination 2: High-Dimensional, Performance-Critical Applications**\n",
    "\n",
    "- **`vectorIndexType`**: `diskANN`\n",
    "- **`datatype`**: `float32`\n",
    "- **`dimensions`**: 768 - 1536\n",
    "- **`distanceFunction`**: `cosine` or `dot product`\n",
    "\n",
    "**Real-World Scenario:**\n",
    "\n",
    "- **Real-Time Recommendations**: A streaming service uses user and content embeddings (1024 dimensions) to provide instantaneous movie recommendations. DiskANN accelerates search times, offering a smooth user experience despite the large dataset.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Combination 3: Storage-Efficient High-Dimensional Data**\n",
    "\n",
    "- **`vectorIndexType`**: `quantizedFlat`\n",
    "- **`datatype`**: `uint8` or `int8`\n",
    "- **`dimensions`**: 2048\n",
    "- **`distanceFunction`**: `cosine`\n",
    "\n",
    "**Real-World Scenario:**\n",
    "\n",
    "- **Mobile Visual Search**: An app allows users to search for products by uploading photos. High-dimensional image embeddings are quantized to fit the storage constraints of mobile devices, and approximate searches provide quick results.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Combination 4: Precision-Critical Scientific Computing**\n",
    "\n",
    "- **`vectorIndexType`**: `flat`\n",
    "- **`datatype`**: `float32`\n",
    "- **`dimensions`**: 4096\n",
    "- **`distanceFunction`**: `euclidean`\n",
    "\n",
    "**Real-World Scenario:**\n",
    "\n",
    "- **Genomic Data Analysis**: Researchers analyze genetic sequences represented as high-dimensional vectors. Precise Euclidean distance calculations are essential for identifying genetic similarities and mutations.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Combination 5: Medium-Dimensional Data with Storage Constraints**\n",
    "\n",
    "- **`vectorIndexType`**: `quantizedFlat`\n",
    "- **`datatype`**: `uint8`\n",
    "- **`dimensions`**: 500\n",
    "- **`distanceFunction`**: `dot product`\n",
    "\n",
    "**Real-World Scenario:**\n",
    "\n",
    "- **IoT Sensor Data**: A network of sensors generates medium-dimensional vectors representing environmental data. Quantization reduces storage and transmission costs, and dot product calculations help in identifying patterns and anomalies efficiently."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation using Financial Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Containers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "1. **`CompanyData`**\n",
    "\n",
    "    - **Data Types**: `BasicCompanyInfo`, `CompanyOfficer`\n",
    "    - **Partition Key**: `/Cik`\n",
    "    - **Id**: `/Cik` to ensure there is only 1 basic information document per company\n",
    "    - **Vector Paths**: ``\n",
    "    - **Notes**:\n",
    "        - **Optimized for Company Queries**: Facilitates queries and reports scoped to specific companies.\n",
    "        - **Rationale**: Embedding reduces the need for cross-partition queries and improves read performance when retrieving company information along with its officers.\n",
    "\n",
    "\n",
    "2. **`FinancialFilings`**\n",
    "\n",
    "    - **Data Types**: `Form10KSection`, `Form13D`\n",
    "    - **Partition Key**: `/Cik`\n",
    "    - **Id**: `\n",
    "    - **Indexing**:\n",
    "        - **Enable Vector Indexing**: For `Form10KSection` embeddings.\n",
    "    - **Notes**:\n",
    "        - **Efficient Semantic Search**: Supports AI-driven searches over financial filings.\n",
    "\n",
    "3. **`MarketData`**\n",
    "\n",
    "    - **Data Types**: `DailyMarketData`\n",
    "    - **Partition Key**: `/Symbol`\n",
    "    - **Notes**:\n",
    "\n",
    "        - **High Write Throughput**: Allocate sufficient RU/s to handle frequent updates.\n",
    "4. **`Holdings`**\n",
    "\n",
    "    - **Data Types**: `Form13FHolding`\n",
    "    - **Partition Key**: `/Cusip`\n",
    "    - **Alternate Partition Key**: `/ManagerName` if queries are more often by manager.\n",
    "    - **Notes**:\n",
    "\n",
    "        - **Facilitates Cross-Company Queries**: Efficiently retrieve holdings data for reports.\n",
    "5. **`NewsArticles`**\n",
    "\n",
    "    - **Data Types**: `NewsArticle`\n",
    "    - **Partition Key**: `/PublishDate` (e.g., formatted as `yyyy-MM` for monthly partitions)\n",
    "    - **Indexing**:\n",
    "\n",
    "        - **Enable Vector Indexing**: For `ArticleText` embeddings.\n",
    "    - **Notes**:\n",
    "\n",
    "        - **Time-Based Partitioning**: Improves performance for time-bound queries.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classes\n",
    "- Every document that will have vector search has only 1 embedding field\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "#pragma warning disable SKEXP0001,SKEXP0020\n",
    "\n",
    "public class ChatService\n",
    "{\n",
    "    private readonly VectorCollection<ChatThread> _chatThreadCollection;\n",
    "    private readonly VectorCollection<ChatThreadMessage> _chatThreadMessageCollection;\n",
    "    private readonly VectorCollection<CacheItem> _cacheCollection;\n",
    "    private readonly Tokenizer _tokenizer;\n",
    "    private readonly ITextEmbeddingGenerationService _embeddingService;\n",
    "    private readonly IChatCompletionService _chatCompletionService;\n",
    "    private readonly Kernel _semanticKernel;\n",
    "\n",
    "    private const string SystemMessage = \"\"\"\n",
    "\n",
    "    \"\"\";\n",
    "    public ChatService(Kernel semanticKernel)\n",
    "    {\n",
    "        _semanticKernel = semanticKernel;\n",
    "        var vectorStore = _semanticKernel.GetRequiredService<VectorStore>();\n",
    "        _chatThreadCollection = vectorStore.GetContainer<ChatThread>();\n",
    "        _chatThreadMessageCollection = vectorStore.GetContainer<ChatThreadMessage>();\n",
    "        _cacheCollection = vectorStore.GetContainer<CacheItem>();\n",
    "        _tokenizer = _semanticKernel.GetRequiredService<Tokenizer>();\n",
    "        _chatCompletionService = _semanticKernel.GetRequiredService<IChatCompletionService>();\n",
    "        _embeddingService = _semanticKernel.GetRequiredService<ITextEmbeddingGenerationService>();\n",
    "    }\n",
    "\n",
    "    public async IAsyncEnumerable<ChatThreadMessage> GetChatCompletionAsync(ChatThread thread, string userQuery, [EnumeratorCancellation] CancellationToken cancellationToken = default)\n",
    "    {   \n",
    "        var queryMessage = new ChatThreadMessage(\n",
    "            Id: Guid.NewGuid().ToString(),\n",
    "            UserId: thread.UserId,\n",
    "            ThreadId: thread.ThreadId,\n",
    "            MessageContent: new ChatMessageContent(\n",
    "                content: userQuery,\n",
    "                role: AuthorRole.User\n",
    "            )\n",
    "        )\n",
    "        {\n",
    "            Tokens = _tokenizer.CountTokens(userQuery)\n",
    "        };\n",
    "        thread.Messages.Append(queryMessage);\n",
    "        await _chatThreadMessageCollection.UpsertAsync(queryMessage, cancellationToken: cancellationToken);\n",
    "\n",
    "        // Generate embedding for the user query and check the cache\n",
    "        var queryEmbedding = await _embeddingService.GenerateEmbeddingAsync(userQuery, cancellationToken: cancellationToken);\n",
    "        var cacheItems = await _cacheCollection.GetNearestMatchesAsync(\n",
    "            embedding: queryEmbedding,\n",
    "            fields: new string[] { \"id\", \"prompts\", \"completion\" },\n",
    "            limit: 1,\n",
    "            minRelevanceScore: 0.00,\n",
    "            cancellationToken: cancellationToken\n",
    "        ).ToListAsync(cancellationToken);\n",
    "\n",
    "        if(cacheItems.Any())\n",
    "        {\n",
    "            var (cacheItem, relevanceScore) = cacheItems.First();\n",
    "            cacheItem.RegisterHit();\n",
    "            await _cacheCollection.UpsertAsync(cacheItem, cancellationToken: cancellationToken);\n",
    "            var response = new ChatThreadMessage(\n",
    "                Id: Guid.NewGuid().ToString(),\n",
    "                UserId: thread.UserId,\n",
    "                ThreadId: thread.ThreadId,\n",
    "                MessageContent: new ChatMessageContent(\n",
    "                    content: cacheItem.Completion,\n",
    "                    role: AuthorRole.Assistant\n",
    "                )\n",
    "            ) {\n",
    "              CacheHit = true,\n",
    "              Tokens = cacheItem.Tokens       \n",
    "            };\n",
    "            thread.Messages.Append(response);\n",
    "            await _chatThreadMessageCollection.UpsertAsync(response, cancellationToken: cancellationToken);\n",
    "            yield return response;\n",
    "        }\n",
    "        else\n",
    "        {\n",
    "            // Cache miss: perform streaming chat completion\n",
    "            // Initialize a StringBuilder to accumulate the response\n",
    "            var contextWindow = thread.GetContextWindow();\n",
    "            var responseBuilder = new StringBuilder();\n",
    "            // Create a new ChatThreadMessage to hold the streamed content\n",
    "            var streamingResponse = new ChatThreadMessage(\n",
    "                Id: Guid.NewGuid().ToString(),\n",
    "                UserId: thread.UserId,\n",
    "                ThreadId: thread.ThreadId,\n",
    "                MessageContent: new ChatMessageContent(\n",
    "                    content: string.Empty, // Will be filled incrementally\n",
    "                    role: AuthorRole.Assistant\n",
    "                )\n",
    "            )\n",
    "            {\n",
    "                CacheHit = false,\n",
    "                FinishedStream = false\n",
    "            };\n",
    "\n",
    "            // Save the initial streaming message\n",
    "            await _chatThreadMessageCollection.UpsertAsync(streamingResponse, cancellationToken: cancellationToken);\n",
    "\n",
    "            // Stream the response from the chat completion service\n",
    "            await foreach (var partialContent in GetChatCompletionStreamingAsync(thread, userQuery, streamingResponse, responseBuilder, cancellationToken))\n",
    "            {\n",
    "                // Yield each partial message as it's received\n",
    "                yield return streamingResponse;\n",
    "            }\n",
    "\n",
    "            var finalResponseString = responseBuilder.ToString();\n",
    "\n",
    "            // After streaming completes, set the final content and persist\n",
    "            var finalResponse = new ChatThreadMessage(\n",
    "                Id: streamingResponse.Id,\n",
    "                UserId: streamingResponse.UserId,\n",
    "                ThreadId: streamingResponse.ThreadId,\n",
    "                MessageContent: new ChatMessageContent(\n",
    "                    content: finalResponseString,\n",
    "                    role: AuthorRole.Assistant\n",
    "                )\n",
    "            )\n",
    "            {\n",
    "                CacheHit = false,\n",
    "                Tokens = _tokenizer.CountTokens(finalResponseString),\n",
    "                FinishedStream = true\n",
    "            };\n",
    "            // Update the streaming message with the final content\n",
    "            await _chatThreadMessageCollection.UpsertAsync(finalResponse, cancellationToken: cancellationToken);\n",
    "\n",
    "            \n",
    "            // Optionally, add to cache\n",
    "            await AddToCacheAsync(contextWindow, finalResponse.MessageContent.Content, cancellationToken);\n",
    "            \n",
    "            // Yield the final complete message\n",
    "            yield return finalResponse;\n",
    "        }\n",
    "    }\n",
    "\n",
    "    /// <summary>\n",
    "    /// Streams chat completion content from the chat completion service.\n",
    "    /// Updates the streaming response message incrementally.\n",
    "    /// </summary>\n",
    "    private async IAsyncEnumerable<string> GetChatCompletionStreamingAsync(\n",
    "        ChatThread thread,\n",
    "        string userQuery,\n",
    "        ChatThreadMessage streamingResponse,\n",
    "        StringBuilder responseBuilder,\n",
    "        [EnumeratorCancellation] CancellationToken cancellationToken = default)\n",
    "    {\n",
    "        // Call the chat completion service to get streaming content\n",
    "        await foreach (var partialContent in _chatCompletionService.GetStreamingChatMessageContentsAsync(\n",
    "            chatHistory: thread,\n",
    "            kernel: this._semanticKernel,\n",
    "            cancellationToken: cancellationToken))\n",
    "        {\n",
    "            // Append the partial content to the response builder\n",
    "            responseBuilder.Append(partialContent.Content);\n",
    "\n",
    "            // Update the streaming response's content\n",
    "            streamingResponse.MessageContent.InnerContent = responseBuilder.ToString();\n",
    "\n",
    "            // Optionally, update token count\n",
    "            streamingResponse.Tokens = _tokenizer.CountTokens(responseBuilder.ToString());\n",
    "\n",
    "            // Optionally, persist the updated streaming response while streaming\n",
    "            // await _chatThreadMessageCollection.UpsertAsync(streamingResponse, cancellationToken: cancellationToken);\n",
    "\n",
    "            // Yield the updated streaming response\n",
    "            yield return partialContent.Content;\n",
    "        }\n",
    "    }\n",
    "\n",
    "    public async Task<ChatThread> CreateChatThreadAsync(string userId, string displayName, CancellationToken cancellationToken = default)\n",
    "    {\n",
    "        var thread = new ChatThread(\n",
    "            ThreadId: Guid.NewGuid().ToString(),\n",
    "            UserId: userId,\n",
    "            DisplayName: displayName\n",
    "        );\n",
    "        await _chatThreadCollection.UpsertAsync(thread, cancellationToken: cancellationToken);\n",
    "        return thread;\n",
    "    }\n",
    "\n",
    "    public async Task<ChatThread> GetChatThreadAsync(ChatThread thread, int maxMessages = 50, CancellationToken cancellationToken = default)\n",
    "    {\n",
    "        var foundThread = await _chatThreadCollection.GetAsync(thread, cancellationToken);\n",
    "        if (thread == null)\n",
    "            throw new KeyNotFoundException($\"ChatThread with ID {thread.Id} not found.\");\n",
    "            \n",
    "        var messages = GetRecentMessagesForThreadAsync(foundThread, maxMessages, cancellationToken);\n",
    "        foundThread.Messages = await messages.ToListAsync(cancellationToken);\n",
    "        return thread;\n",
    "    }\n",
    "\n",
    "    public async Task<List<ChatThread>> GetChatThreadsForUser(string userId, int maxResults = 10, CancellationToken cancellationToken = default)\n",
    "    {   \n",
    "        List<ChatThread> results = new();\n",
    "        var items = _chatThreadCollection.FindItems(\n",
    "          predicate: (x) => x.UserId == userId && x.Type == \"ChatThread\", \n",
    "          select: (s) => new { s.Id, s.UserId, s.DisplayName, s.Type }, \n",
    "          maxResults: maxResults, \n",
    "          cancellationToken: cancellationToken);\n",
    "\n",
    "        await foreach (var item in items)\n",
    "        {\n",
    "            results.Add(item);\n",
    "        }\n",
    "        return results;\n",
    "    } \n",
    "\n",
    "    /// <summary>\n",
    "    /// Retrieves recent messages from the active chat thread within the token limit.\n",
    "    /// </summary>\n",
    "    private async IAsyncEnumerable<ChatThreadMessage> GetRecentMessagesForThreadAsync(ChatThread thread, int maxItems = 50, [EnumeratorCancellation] CancellationToken cancellationToken = default)\n",
    "    {\n",
    "        List<ChatThreadMessage> messages = new();\n",
    "\n",
    "        var items = _chatThreadMessageCollection.FindItems(\n",
    "            predicate: (x) => x.UserId == thread.UserId && x.ThreadId == thread.ThreadId && x.Type == \"ChatThreadMessage\",\n",
    "            select: (s) => new { s.Id, s.ThreadId, s.MessageContent, s.Tokens, s.CreatedAt, s.Type },\n",
    "            maxResults: maxItems,\n",
    "            cancellationToken: cancellationToken\n",
    "        );\n",
    "\n",
    "        await foreach (var item in items)\n",
    "        {\n",
    "            yield return item;\n",
    "        }\n",
    "    }\n",
    "    /// <summary>\n",
    "    /// Adds a new cache item to the cache collection.\n",
    "    /// </summary>\n",
    "    private async Task AddToCacheAsync(string contextWindow, string completion, CancellationToken cancellationToken = default)\n",
    "    {\n",
    "        // Generate embedding for the contextWindow\n",
    "        var embedding = await _embeddingService.GenerateEmbeddingAsync(contextWindow, cancellationToken: cancellationToken);\n",
    "        var cacheItem = new CacheItem(\n",
    "            Id: Guid.NewGuid().ToString(),\n",
    "            Prompts: contextWindow,\n",
    "            Completion: completion,\n",
    "            Embedding: embedding\n",
    "        );\n",
    "\n",
    "        await _cacheCollection.UpsertAsync(cacheItem, updateEmbeddingFields: false, cancellationToken);\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "#pragma warning disable SKEXP0001,SKEXP0020\n",
    "\n",
    "public class CompanyFinancialsAgent\n",
    "{\n",
    "    public const string AgentName = \"CompanyFinancialsAgent\";\n",
    "\n",
    "    private readonly VectorCollection<CompanyInfo> _companyInfoCollection;\n",
    "    \n",
    "    public CompanyFinancialsAgent(Kernel semanticKernel)\n",
    "    {\n",
    "        var vectorStore = semanticKernel.GetRequiredService<VectorStore>();\n",
    "        _companyInfoCollection = vectorStore.GetContainer<CompanyInfo>();\n",
    "    }\n",
    "\n",
    "\n",
    "}\n",
    "\n",
    "var database = cosmosNoSqlService.databaseClient;\n",
    "skBuilder.Services.AddTransient(sp => {\n",
    "  var database = cosmosNoSqlService.databaseClient;\n",
    "  var tokenizer = sp.GetRequiredService<Tokenizer>();\n",
    "  var textEmbeddingService = sp.GetRequiredService<ITextEmbeddingGenerationService>();\n",
    "  return new VectorStore(database, tokenizer, textEmbeddingService);\n",
    "});\n",
    "skBuilder.Services.AddKeyedSingleton<ChatCompletionAgent>(CompanyFinancialsAgent.AgentName, (sp,key) => new ChatCompletionAgent(){\n",
    "  Instructions = \"\",\n",
    "  Name = \"\",\n",
    "  Kernel = sp.GetRequiredService<Kernel>().Clone(),\n",
    "});\n",
    "var skInstance = skBuilder.Build();\n",
    "var ragContextBuilder = new RagContextBuilder(skInstance);\n",
    "// var vectorStore = skInstance.GetRequiredService<VectorStore>();\n",
    "// await vectorStore.CreateContainers(); "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantic Search on Cosmos DB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Structured Database Copilot\n",
    "NL2SQL - Database query generation\n",
    "\n",
    "### Considerations\n",
    "- Usually good at building most of the database query, however it needs prompt tuning or native functions to improve the where clause.\n",
    "\n",
    "**Example User Stories**\n",
    "- I have application monitoring or metric data that I want to derive insights from. \n",
    "- I want to chat over the entire corpus of Service Now or other ICM support ticket information"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".NET (C#)",
   "language": "C#",
   "name": ".net-csharp"
  },
  "language_info": {
   "name": "python"
  },
  "polyglot_notebook": {
   "kernelInfo": {
    "defaultKernelName": "csharp",
    "items": [
     {
      "aliases": [],
      "name": "csharp"
     }
    ]
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
