{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline RAG\n",
    "There are many pre-existing documents, examples, and accelerators demonstrating Retrieval-Augmented Generation (RAG) with Large Language Models (LLMs). This solution is meant to build on these materials, providing implementation specifics for a complete solution.\n",
    "\n",
    "*For general guidance on RAG*\n",
    "  - [Retrieval Augmented Generation using Azure Machine Learning prompt flow (preview)](https://learn.microsoft.com/en-us/azure/machine-learning/concept-retrieval-augmented-generation?view=azureml-api-2)\n",
    "  - [Retrieval Augmented Generation (RAG) in Azure AI Search](https://learn.microsoft.com/en-us/azure/search/retrieval-augmented-generation-overview)\n",
    "  - [Azure Enterprise RAG Accelerator](https://aka.ms/gpt-rag)\n",
    "\n",
    "## Key Topics\n",
    "\n",
    "1. **Semantic Search:** Comparing different approaches of semantic search over structured data, unstructured data, text, and embeddings.\n",
    "\n",
    "1. **Noise, Data Size, Data Velocity:** Searching over large sets of data can cause noise in the grounding context. Similarly, how do you handle datasets with a high velocity of data changes.\n",
    "\n",
    "1. **Data stores:** Which data stores should be used in various scenarios.\n",
    "\n",
    "1. **Security:** Implementing record-level security around data retreival in conversational applications.\n",
    "\n",
    "1. **Performance:** How to evaluate the performance of retreival techniques and solutions to improve performance.\n",
    "\n",
    "## Considerations\n",
    "\n",
    "**Alternative solutions**\n",
    "- Basic Semantic Search fails when answers require piecing together information from more than a few sources or when the queries are abstract (e.g. catch me up on the last two weeks of emails)\n",
    "\n",
    "- Large context window (e.g. 1 million tokens++) fails when scale of dataset is too large. \"Lost in the middle\" phenonemon (e.g. \"What creatures are discussed in this podcast series?\")\n",
    "\n",
    "- See [GraphRAG](../graph_rag/solution.ipynb) for handling large context windows and dataset summarization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Guide\n",
    "1. Deploy the following services:\n",
    "    - Deploy Bicep script or bring your own\n",
    "\n",
    "1. Rename the [env.example.json](env.example.json) file to `env.json` and fill in the values.\n",
    "\n",
    "1. Load the Semantic Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div></div><div></div><div><strong>Installed Packages</strong><ul><li><span>Azure.AI.OpenAI, 2.0.0-beta.3</span></li><li><span>Azure.Identity, 1.12.0</span></li><li><span>Azure.Search.Documents, 11.6.0</span></li><li><span>CsvHelper, 33.0.1</span></li><li><span>Microsoft.Azure.Cosmos, 3.42.0</span></li><li><span>Microsoft.Data.Analysis, 0.21.0</span></li><li><span>System.Linq.Async, 6.0.1</span></li></ul></div></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div><div></div><div></div><div><strong>Installed Packages</strong><ul><li><span>Azure.Monitor.OpenTelemetry.Exporter, 1.3.0</span></li><li><span>Microsoft.ML.Tokenizers, 0.22.0-preview.24378.1</span></li><li><span>Microsoft.SemanticKernel, 1.19.0</span></li><li><span>Microsoft.SemanticKernel.Connectors.AzureCosmosDBNoSQL, 1.19.0-alpha</span></li><li><span>Microsoft.SemanticKernel.Connectors.OpenAI, 1.19.0</span></li><li><span>Microsoft.SemanticKernel.Planners.OpenAI, 1.19.0-preview</span></li></ul></div></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#!import code/Setup.cs "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Semantic Memory\n",
    "\n",
    "AI memory structures hold a lot of promise in helping Language Models orchestrate how it approaches problems. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectors and Embeddings \n",
    "\n",
    "\n",
    "#### Do you need a vector database?\n",
    "\n",
    "#### Do you need hybrid search?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "dotnet_interactive": {
     "language": "mermaid"
    },
    "polyglot_notebook": {
     "kernelName": "mermaid"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"mermaidMarkdownContainer\" style=\"background-color:white\">\r\n",
       "<link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.0/css/all.min.css\">\r\n",
       "<div id=\"e78a78eca5cd406e8988932082163524\"></div>\r\n",
       "<script type=\"module\">\r\n",
       "\r\n",
       "            import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@10.6.1/dist/mermaid.esm.min.mjs';\r\n",
       "            let renderTarget = document.getElementById('e78a78eca5cd406e8988932082163524');\r\n",
       "            try {\r\n",
       "                const {svg, bindFunctions} = await mermaid.mermaidAPI.render( \r\n",
       "                    'mermaid_e78a78eca5cd406e8988932082163524', \r\n",
       "                    `graph TD\r\n",
       "    A[User Query] -->|Sends Query| B[Azure AI Search]\r\n",
       "    B -->|Performs Hybrid Search| C[Search Index]\r\n",
       "    C -->|Returns Results| D[Azure AI Search]\r\n",
       "    D -->|Performs Semantic Re-ranking| E[Re-ranked Results]\r\n",
       "    E -->|Returns to User| F[User]`);\r\n",
       "                renderTarget.innerHTML = svg;\r\n",
       "                bindFunctions?.(renderTarget);\r\n",
       "            }\r\n",
       "            catch (error) {\r\n",
       "                console.log(error);\r\n",
       "            }\r\n",
       "</script>\r\n",
       "</div>\r\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "graph TD\n",
    "    A[User Query] -->|Sends Query| B[Azure AI Search]\n",
    "    B -->|Performs Hybrid Search| C[Search Index]\n",
    "    C -->|Returns Results| D[Azure AI Search]\n",
    "    D -->|Performs Semantic Re-ranking| E[Re-ranked Results]\n",
    "    E -->|Returns to User| F[User]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Which database?\n",
    "\n",
    "**Aure Databases supporting vector fields are preferred when:**\n",
    "- You have structured or semi-structured operatational data (e.g. chat history, user profiles) in the database\n",
    "- You need a single source of truth and don't want to synchronize separate databases\n",
    "- You need [OLTP](https://learn.microsoft.com/en-us/azure/architecture/data-guide/relational-data/online-transaction-processing) database characteristics, like atomic transactions and consistency\n",
    "\n",
    "  *Databases supporting vector fields*\n",
    "  - Azure Cosmos DB for NoSQL Integrated Vector - - Database with DiskANN\n",
    "  - Azure Cosmos DB for MongoDB Integrated Vector Database\n",
    "  - Azure SQL Database\n",
    "  - Azure PostgreSQL Server pgvector Extension\n",
    "  - Open-source vector databases\n",
    "\n",
    "**Azure AI Search is preferred when:**\n",
    "- You have both structured & unstructured data (e.g. images, PDFs, text) from a variety of data sources\n",
    "- You require search technology such as semantic re-ranking, multi-language support, hybrid text/vector search, etc.\n",
    "- The consuming application requires a search engine like experience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "#pragma warning disable SKEXP0001\n",
    "// Vector Models\n",
    "using Microsoft.Azure.Cosmos;\n",
    "using Microsoft.SemanticKernel.Connectors.AzureCosmosDBNoSQL;\n",
    "using Microsoft.SemanticKernel.Data;\n",
    "using IndexKind = Microsoft.Azure.Cosmos.IndexKind;\n",
    "using System.Reflection;\n",
    "using System.Text.Json.Serialization;\n",
    "using Azure.Core.Serialization;\n",
    "using Container = Microsoft.Azure.Cosmos.Container;\n",
    "\n",
    "// public record 10KDocument(\n",
    "//     [property: VectorStoreRecordKey] string HotelId,\n",
    "//     [property: VectorStoreRecordData] string HotelName,\n",
    "//     [property: VectorStoreRecordData] string Description,\n",
    "//     [property: VectorStoreRecordVector(Dimensions: 4, IndexKind: IndexKind.Hash, DistanceFunction: DistanceFunction.CosineSimilarity), JsonPropertyName(\"description_embeddings\")] ReadOnlyMemory<float>? DescriptionEmbeddings);\n",
    "\n",
    "\n",
    "public record PartitionedEntity(string PartitionKey, string Type){\n",
    "\n",
    "    [JsonConstructor]\n",
    "    public PartitionedEntity(string PartitionKey, string Type, string Id): this(PartitionKey, Type)\n",
    "    {\n",
    "        this.PartitionKey = PartitionKey;\n",
    "        this.Type = Type;\n",
    "        this.Id = Id;\n",
    "    }\n",
    "    public string Id { get; set; } = null;\n",
    "    public string SourceUri { get; set; } = string.Empty;\n",
    "};\n",
    "\n",
    "public record CompanyOfficer(\n",
    "    int CompanyCIK,\n",
    "    string FirstName,\n",
    "    string LastName,\n",
    "    int? Age,\n",
    "    string Title,\n",
    "    int? YearBorn,\n",
    "    long TotalPay\n",
    "): PartitionedEntity(CompanyCIK.ToString(), \"CompanyOfficer\", $\"{CompanyCIK}_{FirstName + LastName}\");\n",
    "\n",
    "public record BasicCompanyInfo (\n",
    "    string Address1,\n",
    "    string City,\n",
    "    string State,\n",
    "    string Zip,\n",
    "    string Country,\n",
    "    string Phone,\n",
    "    string Website,\n",
    "    string Industry,\n",
    "    string Sector,\n",
    "    string LongBusinessSummary,\n",
    "    ICollection<CompanyOfficer> CompanyOfficers,\n",
    "    string IrWebsite,\n",
    "    string Exchange,\n",
    "    string QuoteType,\n",
    "    string TickerSymbol,\n",
    "    string UnderlyingSymbol,\n",
    "    string ShortName,\n",
    "    string SecName,\n",
    "    int CIK,\n",
    "    string PrimaryExchange,\n",
    "    ICollection<string> AssociatedCusips\n",
    "): PartitionedEntity(PartitionKey: CIK.ToString(), Type: \"CompanyInfo\", Id: CIK.ToString());\n",
    "\n",
    "var Form10KSections = new Dictionary<string, string>\n",
    "{\n",
    "    { \"item1\", \"Business: requires a description of the company’s business, including its main products and services, what subsidiaries it owns, and what markets it operates in\" },\n",
    "    { \"item1a\", \"Risk Factors: includes information about the most significant risks that apply to the company or to its securities\" },\n",
    "    { \"item1b\", \"Unresolved Staff Comments: requires the company to explain certain comments it has received from the SEC staff on previously filed reports that have not been resolved after an extended period of time\" },\n",
    "    { \"item2\", \"Properties: includes information about the company’s significant properties, such as principal plants, mines and other materially important physical properties\" },\n",
    "    { \"item3\", \"Legal Proceedings: requires the company to include information about significant pending lawsuits or other legal proceedings, other than ordinary litigation\" },\n",
    "    { \"item7\", \"Management’s Discussion and Analysis of Financial Condition and Results of Operations (MD&A): gives the company’s perspective on the business results of the past financial year. This section, known as the MD&A for short, allows company management to tell its story in its own words\" },\n",
    "    { \"item7a\", \"Quantitative and Qualitative Disclosures About Market Risk: requires information about the company’s exposure to market risk, such as interest rate risk, foreign currency exchange risk, commodity price risk or equity price risk\" },\n",
    "    { \"item8\", \"Financial Statements and Supplementary Data: requires the company’s audited financial statements\" },\n",
    "    { \"item10\", \"Directors, Executive Officers and Corporate Governance: requires information about the background and experience of the company’s directors and executive officers, the company’s code of ethics, and certain qualifications for directors and committees of the board of directors\" },\n",
    "    { \"item11\", \"Executive Compensation: includes detailed disclosure about the company’s compensation policies and programs and how much compensation was paid to the top executive officers of the company in the past year\" },\n",
    "    { \"item15\", \"Exhibits, Financial Statement Schedules: Many exhibits are required, including documents such as the company’s bylaws, copies of its material contracts, and a list of the company’s subsidiaries\" }\n",
    "};\n",
    "public record SecForm10KSection(int CIK, DateTime FilingDate, string SectionName, string SectionShortName, string SectionText, ReadOnlyMemory<float> ContentEmbedding): PartitionedEntity(CIK.ToString(), \"10-K\", $\"{CIK}_{FilingDate}_{SectionName}\");\n",
    "public record SecForm13FHolding(int CIK, string ManagerName, string SecurityName, int Shares, int Value, string SecurityType, string Cusip, DateTime ReportedDate): PartitionedEntity(Cusip, \"13F-HR\", $\"{Cusip}_{ManagerName}\");\n",
    "public record SecForm13D(int CIK, string ReportingPerson, DateTime FilingDate, string Description): PartitionedEntity(CIK.ToString(), \"13D\");\n",
    "\n",
    "public record DailyMarketData(string Symbol, DateTime Date, float Open, float High, float Low, float Close, long Volume): PartitionedEntity(Symbol, \"DailyMarketData\");\n",
    "public record NewsArticle(string Headline, string ArticleText, string SourceName, string Uri, DateTime PublishDate): PartitionedEntity(SourceName, \"NewsArticle\");\n",
    "\n",
    "\n",
    "// cosmosNoSqlService.BulkUpload()\n",
    "// public class ContextBuilder\n",
    "// {\n",
    "//     readonly int _maxTokens;\n",
    "//     readonly int _maxPromptTokens;\n",
    "//     readonly Dictionary<string, Type> _memoryTypes;\n",
    "//     readonly PromptOptimizationSettings? _promptOptimizationSettings;\n",
    "\n",
    "//     const int BufferTokens = 50;\n",
    "\n",
    "//     string _systemPrompt = string.Empty;\n",
    "//     List<object> _memories = new List<object>();\n",
    "//     List<(AuthorRole AuthorRole, string Content)> _messages = new List<(AuthorRole AuthorRole, string Content)>();\n",
    "\n",
    "//     public ContextBuilder(\n",
    "//         int maxTokens,\n",
    "//         Dictionary<string, Type> memoryTypes,\n",
    "//         ITokenizer? tokenizer = null,\n",
    "//         PromptOptimizationSettings? promptOptimizationSettings = null) \n",
    "//     {\n",
    "//         _maxTokens = maxTokens;\n",
    "//         _memoryTypes = memoryTypes;\n",
    "\n",
    "//         // If no external tokenizer has been provided, use our own\n",
    "//         _tokenizer = tokenizer ?? new MicrosoftMLTokenizer();\n",
    "        \n",
    "//         _promptOptimizationSettings = promptOptimizationSettings != null\n",
    "//             ? promptOptimizationSettings\n",
    "//             : new PromptOptimizationSettings \n",
    "//             {\n",
    "//                 CompletionsMinTokens = 50,\n",
    "//                 CompletionsMaxTokens = 300,\n",
    "//                 SystemMaxTokens = 1500,\n",
    "//                 MemoryMinTokens = 500,\n",
    "//                 MemoryMaxTokens = 2500,\n",
    "//                 MessagesMinTokens = 1000,\n",
    "//                 MessagesMaxTokens = 3000\n",
    "//             };\n",
    "\n",
    "//         // Use BufferTokens (default 50) tokens as a buffer for extra needs resulting from concatenation, new lines, etc.\n",
    "//         _maxPromptTokens = _maxTokens - _promptOptimizationSettings.CompletionsMaxTokens - BufferTokens;\n",
    "//     }\n",
    "\n",
    "//     public ContextBuilder WithSystemPrompt(string prompt)\n",
    "//     {\n",
    "//         ArgumentNullException.ThrowIfNullOrEmpty(prompt, nameof(prompt));\n",
    "//         _systemPrompt = prompt;\n",
    "//         return this;\n",
    "//     }\n",
    "\n",
    "//     public ContextBuilder WithMemories(List<string> memories)\n",
    "//     {\n",
    "//         ArgumentNullException.ThrowIfNull(memories, nameof(memories));\n",
    "\n",
    "//         // This function transforms the JSON into a more streamlined string of text, more suitable for generating responses\n",
    "//         // Use by default the JSON text representation based on EmbeddingFieldAttribute\n",
    "//         // TODO: Test also using the more elaborate text representation - itemToEmbed.TextToEmbed\n",
    "//         _memories = memories.Select(m => (object) EmbeddingUtility.Transform(m, _memoryTypes).TextToEmbed).ToList();\n",
    "//         return this;\n",
    "//     }\n",
    "\n",
    "//     public ContextBuilder WithMessageHistory(List<(AuthorRole AuthorRole, string Content)> messages) \n",
    "//     {\n",
    "//         ArgumentNullException.ThrowIfNull(messages, nameof(messages));\n",
    "//         _messages = messages;\n",
    "//         return this;\n",
    "//     }\n",
    "\n",
    "//     public string Build()\n",
    "//     {\n",
    "//         OptimizePromptSize();\n",
    "\n",
    "//         var result = new StringBuilder();\n",
    "\n",
    "//         if (_memories.Count > 0)\n",
    "//         {\n",
    "//             var memoriesPrompt = string.Join(Environment.NewLine, _memories.Select(\n",
    "//                 m => $\"{JsonConvert.SerializeObject(m)}{Environment.NewLine}---------------------------{Environment.NewLine}\").ToArray());\n",
    "//             result.Append($\"Context:{Environment.NewLine}{Environment.NewLine}{memoriesPrompt}{Environment.NewLine}{Environment.NewLine}\".NormalizeLineEndings());\n",
    "//         }\n",
    "\n",
    "//         if (_messages.Count > 0)\n",
    "//         {\n",
    "//             result.Append($\"The history of the current conversation is:{Environment.NewLine}{Environment.NewLine}\".NormalizeLineEndings());\n",
    "//             foreach (var message in _messages)\n",
    "//                 result.Append($\"{message.AuthorRole}: {message.Content}{Environment.NewLine}\".NormalizeLineEndings());\n",
    "//         }\n",
    "\n",
    "//         return result.ToString();\n",
    "//     }\n",
    "\n",
    "//     private void OptimizePromptSize()\n",
    "//     {\n",
    "//         var systemPromptTokens = _tokenizer!.GetTokensCount(_systemPrompt);\n",
    "\n",
    "//         var memories = _memories.Select(m => new\n",
    "//         {\n",
    "//             Memory = m,\n",
    "//             Tokens = _tokenizer.GetTokensCount(JsonConvert.SerializeObject(m).NormalizeLineEndings())\n",
    "//         }).ToList();\n",
    "\n",
    "//         // Keep in reverse order because we need to keep the most recents messages\n",
    "//         var messages = _messages.Select(m => new\n",
    "//         {\n",
    "//             Message = m,\n",
    "//             Tokens = _tokenizer.GetTokensCount(m.Content)\n",
    "//         }).Reverse().ToList();\n",
    "\n",
    "//         // All systems green?\n",
    "//         var totalTokens = systemPromptTokens + memories.Sum(mt => mt.Tokens) + messages.Sum(mt => mt.Tokens) + BufferTokens;\n",
    "//         if (totalTokens <= _maxPromptTokens)\n",
    "//             // We're good, not reaching the limit\n",
    "//             return;\n",
    "\n",
    "//         // Start trimming down things to fit within the defined constraints\n",
    "\n",
    "//         if (systemPromptTokens > _promptOptimizationSettings!.SystemMaxTokens)\n",
    "//             throw new Exception($\"The estimated size of the core system prompt ({systemPromptTokens} tokens) exceeds the configured maximum of {_promptOptimizationSettings.SystemMaxTokens}.\");\n",
    "\n",
    "//         // Limit memories\n",
    "\n",
    "//         var tmpMemoryTokens = 0;\n",
    "//         var validMemoriesCount = 0;\n",
    "\n",
    "//         foreach (var m in memories)\n",
    "//         {\n",
    "//             tmpMemoryTokens += m.Tokens;\n",
    "//             if (tmpMemoryTokens <= _promptOptimizationSettings.MemoryMaxTokens)\n",
    "//                 validMemoriesCount++;\n",
    "//             else\n",
    "//                 break;\n",
    "//         }\n",
    "\n",
    "//         // Keep the memories that allow us to obey the limit rule (still in reverse order as we might need to further limit)\n",
    "//         memories = memories.Take(validMemoriesCount).ToList();\n",
    "//         _memories = memories.Select(m => m.Memory).ToList();\n",
    "\n",
    "//         var tmpMessagesTokens = 0;\n",
    "//         var validMessagesCount = 0;\n",
    "\n",
    "//         foreach(var m in messages)\n",
    "//         {\n",
    "//             tmpMessagesTokens += m.Tokens;\n",
    "//             if (tmpMessagesTokens <= _promptOptimizationSettings.MessagesMaxTokens)\n",
    "//                 validMessagesCount++;\n",
    "//             else\n",
    "//                 break;\n",
    "//         }\n",
    "\n",
    "//         // Keep the messages that allow us to obey the limit rule (still in reverse order as we might need to further limit)\n",
    "//         messages = messages.Take(validMessagesCount).ToList();\n",
    "//         _messages = messages.Select(m => m.Message).Reverse().ToList();\n",
    "\n",
    "//         // All systems green?\n",
    "//         var memoryTokens = memories.Sum(mt => mt.Tokens);\n",
    "//         var messagesTokens = messages.Sum(mt => mt.Tokens);\n",
    "//         totalTokens = systemPromptTokens + memoryTokens + messagesTokens + BufferTokens;\n",
    "//         if (totalTokens <= _maxPromptTokens)\n",
    "//             // We're good, just got below the overall limit using the configured max limits for memories and messages\n",
    "//             return;\n",
    "\n",
    "//         // Still not good, so continue trimming down things\n",
    "\n",
    "//         // Eliminate one memory at a time in reverse order until we either reach the token goal or we fall bellow the minimum memory token count\n",
    "//         for (int i = memories.Count - 1; i >= 0; i--)\n",
    "//         {\n",
    "//             if (memoryTokens - memories[i].Tokens < _promptOptimizationSettings.MemoryMinTokens\n",
    "//                 || totalTokens <= _maxPromptTokens)\n",
    "//             // This memory will not be eliminated because we've either got below the overall limit or its elimination will get us below the minimum memory token count\n",
    "//             {\n",
    "//                 memories = memories.Take(i + 1).ToList();\n",
    "//                 _memories = memories.Select(m => m.Memory).ToList();\n",
    "//                 memoryTokens = memories.Sum(mt => mt.Tokens);\n",
    "//                 break;\n",
    "//             }\n",
    "\n",
    "//             memoryTokens -= memories[i].Tokens;\n",
    "//             totalTokens -= memories[i].Tokens;\n",
    "//         }\n",
    "\n",
    "//         // All systems green?\n",
    "//         totalTokens = systemPromptTokens + memoryTokens + messagesTokens + BufferTokens;\n",
    "//         if (totalTokens <= _maxPromptTokens)\n",
    "//             // We're good, just got below the overall limit without reaching the lower limit for memory tokens\n",
    "//             return;\n",
    "\n",
    "//         // Still not good, so continue trimming down things\n",
    "\n",
    "//         // Eliminate one message at a time in reverse order until we either reach the token goal or we fall bellow the minimum memory token count\n",
    "//         for (int i = messages.Count - 1; i > 0; i--)\n",
    "//         {\n",
    "//             if (messagesTokens - messages[i].Tokens < _promptOptimizationSettings.MessagesMinTokens\n",
    "//                 || totalTokens <= _maxPromptTokens)\n",
    "//             // This message will not be eliminated because we've either got below the overall limit or its elimination will get us below the minimum messages token count\n",
    "//             {\n",
    "//                 messages = messages.Take(i + 1).ToList();\n",
    "//                 _messages = messages.Select(m => m.Message).Reverse().ToList();\n",
    "//                 messagesTokens = messages.Sum(mt => mt.Tokens);\n",
    "//                 break;\n",
    "//             }\n",
    "\n",
    "//             messagesTokens -= messages[i].Tokens;\n",
    "//             totalTokens -= messages[i].Tokens;\n",
    "//         }\n",
    "\n",
    "//         // All systems green?\n",
    "//         totalTokens = systemPromptTokens + memoryTokens + messagesTokens + BufferTokens;\n",
    "//         if (totalTokens <= _maxPromptTokens)\n",
    "//             // We're good, just got below the overall limit without reaching the lower limit for messages tokens\n",
    "//             return;\n",
    "\n",
    "//         // Oops! The least significant memory and the least significant message are preventing us from getting below the overall limit\n",
    "\n",
    "//         // Remove the least significant memory\n",
    "//         totalTokens -= memories.Last().Tokens;\n",
    "//         memories.RemoveAt(memories.Count - 1);\n",
    "//         _memories = memories.Select(m => m.Memory).ToList();\n",
    "\n",
    "//         // All systems green?\n",
    "//         if (totalTokens <= _maxPromptTokens)\n",
    "//             // We're good, just got below the overall limit by removing the least significant memory\n",
    "//             return;\n",
    "\n",
    "//         // Remove the least significant message\n",
    "//         totalTokens -= messages.Last().Tokens;\n",
    "//         messages.RemoveAt(messages.Count - 1);\n",
    "//         _messages = messages.Select(m => m.Message).Reverse().ToList();\n",
    "\n",
    "//         // All systems green?\n",
    "//         if (totalTokens <= _maxPromptTokens)\n",
    "//             // We're good, just got below the overall limit by removing the least significant message\n",
    "//             return;\n",
    "\n",
    "//         // Error! Most likely, the prompt optimization settings are inconsistent\n",
    "//         throw new Exception(\"Cannot produce a prompt using the current prompt optimization settings.\");\n",
    "//     }\n",
    "\n",
    "\n",
    "// }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **CosmosDB: Understand Index Type and Distance Functions**\n",
    "---\n",
    "#### **1. `Vector Index Type`**\n",
    "\n",
    "This option determines how vectors are indexed within Cosmos DB to optimize search performance.\n",
    "<details>\n",
    "<summary>\n",
    "Options\n",
    "</summary>\n",
    "\n",
    "- **`flat`**: Stores vectors alongside other indexed properties without additional indexing structures. Supports up to **505 dimensions**.\n",
    "\n",
    "  **When to Use:**\n",
    "\n",
    "  - **Low-dimensional data**: Ideal for applications with vectors up to 505 dimensions.\n",
    "  - **Exact search requirements**: When you need precise search results.\n",
    "  - **Small to medium datasets**: Efficient for datasets where the index size won't become a bottleneck.\n",
    "\n",
    "    **Real-World Scenario:**\n",
    "\n",
    "    - **Customer Segmentation**: A retail company uses customer feature vectors (age, income, purchase history) with dimensions well below 505 to segment customers. Exact matches are important for targeted marketing campaigns.\n",
    "\n",
    "- **`quantizedFlat`**: Compresses (quantizes) vectors before indexing, improving performance at the cost of some accuracy. Supports up to **4096 dimensions**.\n",
    "\n",
    "  **When to Use:**\n",
    "\n",
    "  - **High-dimensional data with storage constraints**: Suitable for vectors up to 4096 dimensions where storage efficiency is important.\n",
    "  - **Performance-critical applications**: When reduced latency and higher throughput are needed.\n",
    "  - **Acceptable accuracy trade-off**: Minor losses in accuracy are acceptable for performance gains.\n",
    "\n",
    "    **Real-World Scenario:**\n",
    "\n",
    "    - **Mobile Image Recognition**: An app recognizes objects using high-dimensional image embeddings. Quantization reduces the storage footprint and improves search speed, crucial for mobile devices with limited resources.\n",
    "\n",
    "- **`diskANN`**: Utilizes the DiskANN algorithm for approximate nearest neighbor searches, optimized for speed and efficiency. Supports up to **4096 dimensions**.\n",
    "\n",
    "  **When to Use:**\n",
    "\n",
    "  - **Large-scale, high-dimensional data**: Best for big datasets where quick approximate searches are acceptable.\n",
    "  - **Real-time applications**: When fast response times are critical.\n",
    "  - **Scalability needs**: Suitable for applications expected to grow significantly.\n",
    "\n",
    "  **Real-World Scenario:**\n",
    "\n",
    "  - **Semantic Search Engines**: A search engine indexes millions of documents using embeddings from language models like BERT (768 dimensions). DiskANN allows users to get fast search results by efficiently handling high-dimensional data.\n",
    "</details>\n",
    "\n",
    "---\n",
    "\n",
    "#### **2. `Vector Data Type`**\n",
    "\n",
    "Specifies the data type of the vector components.\n",
    "<details>\n",
    "<summary>Options</summary>\n",
    "\n",
    "- **`float32`** (default): 32-bit floating-point numbers.\n",
    "\n",
    "  **When to Use:**\n",
    "\n",
    "  - **High precision requirements**: Necessary when the application demands precise calculations.\n",
    "  - **Standard ML embeddings**: Most machine learning models output float32 vectors.\n",
    "\n",
    "  **Real-World Scenario:**\n",
    "\n",
    "  - **Scientific Simulations**: In climate modeling, vectors represent complex data where precision is vital for accurate simulations and predictions.\n",
    "\n",
    "- **`uint8`**: 8-bit unsigned integers.\n",
    "\n",
    "  **When to Use:**\n",
    "\n",
    "  - **Memory optimization**: Reduces storage needs when precision can be sacrificed.\n",
    "  - **Quantized models**: When vectors are output from models that already quantize data.\n",
    "\n",
    "  **Real-World Scenario:**\n",
    "\n",
    "  - **Basic Image Features**: Storing color histograms for image retrieval systems, where each bin can be represented with an 8-bit integer.\n",
    "\n",
    "- **`uint8`**: 8-bit integer with potentially specialized encoding (interpretation may vary; assuming it's an 8-bit integer with logarithmic encoding).\n",
    "\n",
    "  **When to Use:**\n",
    "\n",
    "  - **Custom quantization schemes**: When using specialized compression techniques that map floating-point values to an 8-bit integer scale.\n",
    "  - **Edge devices**: Ideal for applications on devices with extreme memory limitations.\n",
    "\n",
    "  **Real-World Scenario:**\n",
    "\n",
    "  - **Audio Fingerprinting**: Compressing audio feature vectors for song recognition apps where storage and quick retrieval are essential.\n",
    "</details>\n",
    "\n",
    "---\n",
    "#### **3. `Dimension Size`**\n",
    "\n",
    "The length of the vectors being indexed. Ranges from 0-4096, default is **1536**.\n",
    "<details>\n",
    "<summary>Options</summary>\n",
    "\n",
    "\n",
    "**When to Consider Lower Dimensions (≤ 505):**\n",
    "\n",
    "  - **Simpler models**: Applications using basic embeddings or feature vectors.\n",
    "  - **Flat index type**: Required when using the `flat` index type due to its dimension limit.\n",
    "\n",
    "  *Real-World Scenario:*\n",
    "\n",
    "  - **Keyword Matching**: Using low-dimensional TF-IDF vectors for document similarity in a content management system.\n",
    "\n",
    "  **When to Consider Higher Dimensions (506 - 4096):**\n",
    "\n",
    "  - **Complex models**: Deep learning applications with high-dimensional embeddings.\n",
    "  - **Advanced search features**: When richer representations of data are necessary for accuracy.\n",
    "\n",
    "  *Real-World Scenario:*\n",
    "\n",
    "  - **Face Recognition**: Using high-dimensional embeddings (e.g., 2048 dimensions) to represent facial features for security systems.\n",
    "</details>\n",
    "\n",
    "---\n",
    "\n",
    "#### **4. `Distance Function`**\n",
    "\n",
    "Determines how similarity between vectors is calculated.\n",
    "<details>\n",
    "<summary>Options</summary>\n",
    "\n",
    "- **`cosine`**: Measures the cosine of the angle between vectors.\n",
    "\n",
    "  **When to Use:**\n",
    "\n",
    "  - **Orientation-focused similarity**: When the magnitude is less important than the direction.\n",
    "  - **Normalized data**: Ideal when vectors are normalized to unit length.\n",
    "\n",
    "  **Real-World Scenario:**\n",
    "\n",
    "  - **Document Similarity**: In text analytics, comparing documents based on topic similarity where word counts are normalized.\n",
    "\n",
    "- **`dot product`**: Computes the scalar product of two vectors.\n",
    "\n",
    "  **When to Use:**\n",
    "\n",
    "  - **Magnitude matters**: When both direction and magnitude are significant.\n",
    "  - **Machine learning models**: Often used in recommendation systems where strength of preferences is important.\n",
    "\n",
    "  **Real-World Scenario:**\n",
    "\n",
    "  - **Personalized Recommendations**: Matching users to products by calculating the dot product of user and item embeddings in a collaborative filtering system.\n",
    "\n",
    "- **`euclidean`**: Calculates the straight-line distance between vectors.\n",
    "\n",
    "  **When to Use:**\n",
    "\n",
    "  - **Spatial distance relevance**: When physical distance correlates with similarity.\n",
    "  - **High-dimensional data**: Suitable for embeddings where both magnitude and direction impact similarity.\n",
    "\n",
    "  **Real-World Scenario:**\n",
    "\n",
    "  - **Anomaly Detection**: Identifying outliers in network traffic patterns by measuring Euclidean distances in feature space.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### **CosmosDB: Option Combinations and Their Preferred Use-Cases**\n",
    "\n",
    "---\n",
    "\n",
    "#### **Combination 1: Low-Dimensional, Exact Searches**\n",
    "\n",
    "- **`vectorIndexType`**: `flat`\n",
    "- **`datatype`**: `float32`\n",
    "- **`dimensions`**: ≤ 505\n",
    "- **`distanceFunction`**: `cosine`\n",
    "\n",
    "**Real-World Scenario:**\n",
    "\n",
    "- **Small-Scale Text Classification**: A startup builds a news categorization tool using word embeddings (300 dimensions). Exact cosine similarity searches ensure accurate article tagging without the overhead of approximate methods.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Combination 2: High-Dimensional, Performance-Critical Applications**\n",
    "\n",
    "- **`vectorIndexType`**: `diskANN`\n",
    "- **`datatype`**: `float32`\n",
    "- **`dimensions`**: 768 - 1536\n",
    "- **`distanceFunction`**: `cosine` or `dot product`\n",
    "\n",
    "**Real-World Scenario:**\n",
    "\n",
    "- **Real-Time Recommendations**: A streaming service uses user and content embeddings (1024 dimensions) to provide instantaneous movie recommendations. DiskANN accelerates search times, offering a smooth user experience despite the large dataset.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Combination 3: Storage-Efficient High-Dimensional Data**\n",
    "\n",
    "- **`vectorIndexType`**: `quantizedFlat`\n",
    "- **`datatype`**: `uint8` or `iln8`\n",
    "- **`dimensions`**: 2048\n",
    "- **`distanceFunction`**: `cosine`\n",
    "\n",
    "**Real-World Scenario:**\n",
    "\n",
    "- **Mobile Visual Search**: An app allows users to search for products by uploading photos. High-dimensional image embeddings are quantized to fit the storage constraints of mobile devices, and approximate searches provide quick results.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Combination 4: Precision-Critical Scientific Computing**\n",
    "\n",
    "- **`vectorIndexType`**: `flat`\n",
    "- **`datatype`**: `float32`\n",
    "- **`dimensions`**: 4096\n",
    "- **`distanceFunction`**: `euclidean`\n",
    "\n",
    "**Real-World Scenario:**\n",
    "\n",
    "- **Genomic Data Analysis**: Researchers analyze genetic sequences represented as high-dimensional vectors. Precise Euclidean distance calculations are essential for identifying genetic similarities and mutations.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Combination 5: Medium-Dimensional Data with Storage Constraints**\n",
    "\n",
    "- **`vectorIndexType`**: `quantizedFlat`\n",
    "- **`datatype`**: `uint8`\n",
    "- **`dimensions`**: 500\n",
    "- **`distanceFunction`**: `dot product`\n",
    "\n",
    "**Real-World Scenario:**\n",
    "\n",
    "- **IoT Sensor Data**: A network of sensors generates medium-dimensional vectors representing environmental data. Quantization reduces storage and transmission costs, and dot product calculations help in identifying patterns and anomalies efficiently."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structured Database Copilot\n",
    "NL2SQL - Database query generation\n",
    "\n",
    "### Considerations\n",
    "- Usually good at building most of the database query, however it needs prompt tuning or native functions to improve the where clause.\n",
    "\n",
    "**Example User Stories**\n",
    "- I have application monitoring or metric data that I want to derive insights from. \n",
    "- I want to chat over the entire corpus of Service Now or other ICM support ticket information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "public class CosmosCopilot {\n",
    "    private readonly CosmosClient _client;\n",
    "    private readonly Container _container;\n",
    "    private readonly ILogger _logger;\n",
    "\n",
    "    public CosmosCopilot(string connectionString, string databaseName, string containerName) {\n",
    "        _client = new CosmosClient(connectionString);\n",
    "        _container = _client.GetContainer(databaseName, containerName);\n",
    "        _logger = NullLogger.Instance;\n",
    "    }\n",
    "\n",
    "    public CosmosCopilot(string connectionString, string databaseName, string containerName, ILogger logger) {\n",
    "        _client = new CosmosClient(connectionString);\n",
    "        _container = _client.GetContainer(databaseName, containerName);\n",
    "        _logger = logger;\n",
    "    }\n",
    "\n",
    "    public async Task<IEnumerable<T>> QueryAsync<T>(string query) {\n",
    "        var iterator = _container.GetItemQueryIterator<T>(query);\n",
    "        var results = new List<T>();\n",
    "        while (iterator.HasMoreResults) {\n",
    "            var response = await iterator.ReadNextAsync();\n",
    "            results.AddRange(response);\n",
    "        }\n",
    "        return results;\n",
    "    }\n",
    "\n",
    "    public async Task<IEnumerable<T>> QueryAsync<T>(QueryDefinition query) {\n",
    "        var iterator = _container.GetItemQueryIterator<T>(query);\n",
    "        var results = new List<T>();\n",
    "        while (iterator.HasMoreResults) {\n",
    "            var response = await iterator.ReadNextAsync();\n",
    "            results.AddRange(response);\n",
    "        }\n",
    "        return results;\n",
    "    }\n",
    "\n",
    "    public async Task<T> GetItemAsync<T>(string partitionKey, string id) {\n",
    "        try {\n",
    "            var response = await _container.ReadItemAsync<T>(id, new PartitionKey(partitionKey));\n",
    "            return response.Resource;\n",
    "        } catch (CosmosException e) {\n",
    "            _logger.LogError(e, \"Error reading item from Cosmos DB\");\n",
    "            return default;\n",
    "        }\n",
    "    }\n",
    "\n",
    "    public async Task<T> UpsertItemAsync<T>(T item) {\n",
    "        try {\n",
    "            var response = await _container.UpsertItemAsync(item);\n",
    "            return response.Resource;\n",
    "        } catch (CosmosException e) {\n",
    "            _logger.LogError(e, \"Error upserting item to Cosmos DB\");\n",
    "            return default;\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Semantic Search Context\n",
    "\n",
    "Security Trimming - https://learn.microsoft.com/en-us/azure/search/search-security-trimming-for-azure-search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple Indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best Practices"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".NET (C#)",
   "language": "C#",
   "name": ".net-csharp"
  },
  "language_info": {
   "name": "python"
  },
  "polyglot_notebook": {
   "kernelInfo": {
    "defaultKernelName": "csharp",
    "items": [
     {
      "aliases": [],
      "name": "csharp"
     }
    ]
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
