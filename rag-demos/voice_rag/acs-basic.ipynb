{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div></div><div></div><div><strong>Installed Packages</strong><ul><li><span>Azure.AI.OpenAI, 2.1.0-beta.1</span></li><li><span>Azure.Identity, 1.13.0-beta.2</span></li><li><span>NAudio, 2.2.1</span></li></ul></div></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#!import code/Setup.cs\n",
    "// Currently ACS is working to enable streaming with OpenAI Realtime, for now this is a placeholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "#pragma warning disable OPENAI002\n",
    "\n",
    "using Azure.AI.OpenAI;\n",
    "using Azure.Identity;\n",
    "using OpenAI;\n",
    "using OpenAI.RealtimeConversation;\n",
    "using System.ClientModel;\n",
    "using NAudio.Wave;\n",
    "using System.Threading;\n",
    "using Microsoft.DotNet.Interactive;\n",
    "using System.Threading.Tasks;\n",
    "\n",
    "AzureOpenAIClient topLevelClient = new(\n",
    "    new Uri(configuration.AzureOpenAIEndpoint),\n",
    "    new ApiKeyCredential(configuration.AzureOpenAIKey));\n",
    "var realtimeConversationClient = topLevelClient.GetRealtimeConversationClient(configuration.AzureOpenAIRealtimeDeployName);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "#pragma warning disable OPENAI002\n",
    "public class MicrophoneAudioStream : Stream, IDisposable\n",
    "{\n",
    "    private const int SAMPLES_PER_SECOND = 24000;\n",
    "    private const int BYTES_PER_SAMPLE = 2;\n",
    "    private const int CHANNELS = 1;\n",
    "\n",
    "    // For simplicity, this is configured to use a static 10-second ring buffer.\n",
    "    private readonly byte[] _buffer = new byte[BYTES_PER_SAMPLE * SAMPLES_PER_SECOND * CHANNELS * 10];\n",
    "    private readonly object _bufferLock = new();\n",
    "    private int _bufferReadPos = 0;\n",
    "    private int _bufferWritePos = 0;\n",
    "\n",
    "    private readonly WaveInEvent _waveInEvent;\n",
    "\n",
    "    private MicrophoneAudioStream()\n",
    "    {\n",
    "        _waveInEvent = new()\n",
    "        {\n",
    "            WaveFormat = new WaveFormat(SAMPLES_PER_SECOND, BYTES_PER_SAMPLE * 8, CHANNELS),\n",
    "        };\n",
    "        _waveInEvent.DataAvailable += (_, e) =>\n",
    "        {\n",
    "            lock (_bufferLock)\n",
    "            {\n",
    "                int bytesToCopy = e.BytesRecorded;\n",
    "                if (_bufferWritePos + bytesToCopy >= _buffer.Length)\n",
    "                {\n",
    "                    int bytesToCopyBeforeWrap = _buffer.Length - _bufferWritePos;\n",
    "                    Array.Copy(e.Buffer, 0, _buffer, _bufferWritePos, bytesToCopyBeforeWrap);\n",
    "                    bytesToCopy -= bytesToCopyBeforeWrap;\n",
    "                    _bufferWritePos = 0;\n",
    "                }\n",
    "                Array.Copy(e.Buffer, e.BytesRecorded - bytesToCopy, _buffer, _bufferWritePos, bytesToCopy);\n",
    "                _bufferWritePos += bytesToCopy;\n",
    "            }\n",
    "        };\n",
    "        _waveInEvent.StartRecording();\n",
    "    }\n",
    "\n",
    "    public static MicrophoneAudioStream Start() => new();\n",
    "\n",
    "    public override bool CanRead => true;\n",
    "\n",
    "    public override bool CanSeek => false;\n",
    "\n",
    "    public override bool CanWrite => false;\n",
    "\n",
    "    public override long Length => throw new NotImplementedException();\n",
    "\n",
    "    public override long Position { get => throw new NotImplementedException(); set => throw new NotImplementedException(); }\n",
    "\n",
    "    public override void Flush()\n",
    "    {\n",
    "        throw new NotImplementedException();\n",
    "    }\n",
    "\n",
    "    public override int Read(byte[] buffer, int offset, int count)\n",
    "    {\n",
    "        int totalCount = count;\n",
    "\n",
    "        int GetBytesAvailable() => _bufferWritePos < _bufferReadPos\n",
    "            ? _bufferWritePos + (_buffer.Length - _bufferReadPos)\n",
    "            : _bufferWritePos - _bufferReadPos;\n",
    "\n",
    "        // For simplicity, we'll block until all requested data is available and not perform partial reads.\n",
    "        while (GetBytesAvailable() < count)\n",
    "        {\n",
    "            Thread.Sleep(100);\n",
    "        }\n",
    "\n",
    "        lock (_bufferLock)\n",
    "        {\n",
    "            if (_bufferReadPos + count >= _buffer.Length)\n",
    "            {\n",
    "                int bytesBeforeWrap = _buffer.Length - _bufferReadPos;\n",
    "                Array.Copy(\n",
    "                    sourceArray: _buffer,\n",
    "                    sourceIndex: _bufferReadPos,\n",
    "                    destinationArray: buffer,\n",
    "                    destinationIndex: offset,\n",
    "                    length: bytesBeforeWrap);\n",
    "                _bufferReadPos = 0;\n",
    "                count -= bytesBeforeWrap;\n",
    "                offset += bytesBeforeWrap;\n",
    "            }\n",
    "\n",
    "            Array.Copy(_buffer, _bufferReadPos, buffer, offset, count);\n",
    "            _bufferReadPos += count;\n",
    "        }\n",
    "\n",
    "        return totalCount;\n",
    "    }\n",
    "\n",
    "    public override long Seek(long offset, SeekOrigin origin)\n",
    "    {\n",
    "        throw new NotImplementedException();\n",
    "    }\n",
    "\n",
    "    public override void SetLength(long value)\n",
    "    {\n",
    "        throw new NotImplementedException();\n",
    "    }\n",
    "\n",
    "    public override void Write(byte[] buffer, int offset, int count)\n",
    "    {\n",
    "        throw new NotImplementedException();\n",
    "    }\n",
    "\n",
    "    protected override void Dispose(bool disposing)\n",
    "    {\n",
    "        _waveInEvent?.Dispose();\n",
    "        base.Dispose(disposing);\n",
    "    }\n",
    "}\n",
    "public class SpeakerOutput : IDisposable\n",
    "{\n",
    "    BufferedWaveProvider _waveProvider;\n",
    "    WaveOutEvent _waveOutEvent;\n",
    "\n",
    "    public SpeakerOutput()\n",
    "    {\n",
    "        WaveFormat outputAudioFormat = new(\n",
    "            rate: 24000,\n",
    "            bits: 16,\n",
    "            channels: 1);\n",
    "        _waveProvider = new(outputAudioFormat)\n",
    "        {\n",
    "            BufferDuration = TimeSpan.FromMinutes(2),\n",
    "        };\n",
    "        _waveOutEvent = new();\n",
    "        _waveOutEvent.Init(_waveProvider);\n",
    "        _waveOutEvent.Play();\n",
    "\n",
    "    }\n",
    "\n",
    "    public void EnqueueForPlayback(BinaryData audioData)\n",
    "    {\n",
    "        byte[] buffer = audioData.ToArray();\n",
    "        _waveProvider.AddSamples(buffer, 0, buffer.Length);\n",
    "    }\n",
    "\n",
    "    public void ClearPlayback()\n",
    "    {\n",
    "        _waveProvider.ClearBuffer();\n",
    "    }\n",
    "\n",
    "    public void Dispose()\n",
    "    {\n",
    "        _waveOutEvent?.Stop();\n",
    "        _waveOutEvent?.Dispose();\n",
    "        _waveProvider?.ClearBuffer();  \n",
    "    }\n",
    "}\n",
    "ConversationFunctionTool finishConversationTool = new()\n",
    "{\n",
    "    Name = \"user_wants_to_finish_conversation\",\n",
    "    Description = \"Invoked when the user says goodbye, expresses being finished, or otherwise seems to want to stop the interaction.\",\n",
    "    Parameters = BinaryData.FromString(\"{}\")\n",
    "};"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " <<< Connected: session started\n",
      " >>> Listening to microphone input\n",
      " >>> (Just tell the app you're done to finish)\n",
      "\n",
      " <<< Start of speech detected\n",
      " <<< End of speech detected\n",
      "Hello! I hear >>> USER: Hello testing this out\n",
      "\n",
      " you loud and clear. Is there anything specific you'd like to test or chat about?\n",
      " <<< Start of speech detected\n",
      " <<< End of speech detected\n",
      "I can help >>> USER: What can you do?\n",
      "\n",
      " answer questions, chat about a variety of topics, tell jokes, provide information, explain concepts, offer advice, and more! What would you like to know or talk about today?\n",
      " <<< Start of speech detected\n",
      " <<< End of speech detected\n",
      " >>> USER: End conversation.\n",
      "\n",
      "\n",
      " <<< Finish tool invoked -- ending conversation!\n",
      "Caught OperationCanceledException.\n"
     ]
    }
   ],
   "source": [
    "#pragma warning disable OPENAI002\n",
    "try\n",
    "{\n",
    "\n",
    "    using SpeakerOutput speakerOutput = new();\n",
    "\n",
    "    using var session = await realtimeConversationClient.StartConversationSessionAsync();\n",
    "    await session.ConfigureSessionAsync(new ConversationSessionOptions()\n",
    "    {\n",
    "        Tools = { finishConversationTool },\n",
    "        InputTranscriptionOptions = new()\n",
    "        {\n",
    "            Model = \"whisper-1\",\n",
    "        },\n",
    "    });\n",
    "    while(!KernelInvocationContext.Current.CancellationToken.IsCancellationRequested)\n",
    "    {\n",
    "        // With the session configured, we start processing commands received from the service.\n",
    "        await foreach (ConversationUpdate update in session.ReceiveUpdatesAsync(KernelInvocationContext.Current.CancellationToken))\n",
    "        {\n",
    "            // session.created is the very first command on a session and lets us know that connection was successful.\n",
    "            if (update is ConversationSessionStartedUpdate)\n",
    "            {\n",
    "                Console.WriteLine($\" <<< Connected: session started\");\n",
    "                // This is a good time to start capturing microphone input and sending audio to the service. The\n",
    "                // input stream will be chunked and sent asynchronously, so we don't need to await anything in the\n",
    "                // processing loop.\n",
    "                _ = Task.Run(async () =>\n",
    "                {\n",
    "                    using MicrophoneAudioStream microphoneInput = MicrophoneAudioStream.Start();\n",
    "                    Console.WriteLine($\" >>> Listening to microphone input\");\n",
    "                    Console.WriteLine($\" >>> (Just tell the app you're done to finish)\");\n",
    "                    Console.WriteLine();\n",
    "                    await session.SendAudioAsync(microphoneInput);\n",
    "                });\n",
    "            }\n",
    "\n",
    "            // input_audio_buffer.speech_started tells us that the beginning of speech was detected in the input audio\n",
    "            // we're sending from the microphone.\n",
    "            if (update is ConversationInputSpeechStartedUpdate)\n",
    "            {\n",
    "                Console.WriteLine($\" <<< Start of speech detected\");\n",
    "                // Like any good listener, we can use the cue that the user started speaking as a hint that the app\n",
    "                // should stop talking. Note that we could also track the playback position and truncate the response\n",
    "                // item so that the model doesn't \"remember things it didn't say\" -- that's not demonstrated here.\n",
    "                speakerOutput.ClearPlayback();\n",
    "            }\n",
    "\n",
    "            // input_audio_buffer.speech_stopped tells us that the end of speech was detected in the input audio sent\n",
    "            // from the microphone. It'll automatically tell the model to start generating a response to reply back.\n",
    "            if (update is ConversationInputSpeechFinishedUpdate)\n",
    "            {\n",
    "                Console.WriteLine($\" <<< End of speech detected\");\n",
    "            }\n",
    "\n",
    "            // conversation.item.input_audio_transcription.completed will only arrive if input transcription was\n",
    "            // configured for the session. It provides a written representation of what the user said, which can\n",
    "            // provide good feedback about what the model will use to respond.\n",
    "            if (update is ConversationInputTranscriptionFinishedUpdate transcriptionFinishedUpdate)\n",
    "            {\n",
    "                Console.WriteLine($\" >>> USER: {transcriptionFinishedUpdate.Transcript}\");\n",
    "            }\n",
    "\n",
    "            // response.audio.delta provides incremental output audio generated by the model talking. Here, we\n",
    "            // immediately enqueue it for playback on the active speaker output.\n",
    "            if (update is ConversationAudioDeltaUpdate audioDeltaUpdate)\n",
    "            {\n",
    "                speakerOutput.EnqueueForPlayback(audioDeltaUpdate.Delta);\n",
    "            }\n",
    "\n",
    "            // response.audio_transcript.delta provides the incremental transcription of the emitted audio. The model\n",
    "            // typically produces output much faster than it should be played back, so the transcript may move very\n",
    "            // quickly relative to what's heard.\n",
    "            if (update is ConversationOutputTranscriptionDeltaUpdate outputTranscriptionDeltaUpdate)\n",
    "            {\n",
    "                Console.Write(outputTranscriptionDeltaUpdate.Delta);\n",
    "            }\n",
    "\n",
    "            // response.output_item.done tells us that a model-generated item with streaming content is completed.\n",
    "            // That's a good signal to provide a visual break and perform final evaluation of tool calls.\n",
    "            if (update is ConversationItemFinishedUpdate itemFinishedUpdate)\n",
    "            {\n",
    "                Console.WriteLine();\n",
    "                if (itemFinishedUpdate.FunctionName == finishConversationTool.Name)\n",
    "                {\n",
    "\n",
    "                    Console.WriteLine($\" <<< Finish tool invoked -- ending conversation!\");\n",
    "                    session.Dispose();\n",
    "                    speakerOutput.Dispose();\n",
    "                    break;\n",
    "                }\n",
    "            }\n",
    "\n",
    "            // error commands, as the name implies, are raised when something goes wrong.\n",
    "            if (update is ConversationErrorUpdate errorUpdate)\n",
    "            {\n",
    "                Console.WriteLine();\n",
    "                Console.WriteLine();\n",
    "                Console.WriteLine($\" <<< ERROR: {errorUpdate.ErrorMessage}\");\n",
    "                Console.WriteLine(errorUpdate.GetRawContent().ToString());\n",
    "                break;\n",
    "            }\n",
    "        }\n",
    "    }\n",
    " \n",
    "\n",
    "}\n",
    "catch (OperationCanceledException)\n",
    "{\n",
    "    Console.WriteLine(\"Caught OperationCanceledException.\");\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".NET (C#)",
   "language": "C#",
   "name": ".net-csharp"
  },
  "language_info": {
   "name": "python"
  },
  "polyglot_notebook": {
   "kernelInfo": {
    "defaultKernelName": "csharp",
    "items": [
     {
      "aliases": [],
      "name": "csharp"
     }
    ]
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
